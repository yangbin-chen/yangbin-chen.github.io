<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Yangbin Chen - Publication</title>

        <meta charset="utf-8">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        
        <!-- Boostrap Core CSS-->
        <link rel="stylesheet" href="css/bootstrap.min.css"> 
        
        <!-- Main CSS -->
        <link rel="stylesheet" href="css/style.css">
        
        <!-- Gallery -->
        <link rel="stylesheet" href="css/touchTouch.css">
        
        <!-- Animate CSS -->
        <link href="css/animate.css" rel="stylesheet">

        <!-- Google fonts -->
        <link href='http://fonts.googleapis.com/css?family=Oxygen:400,300' rel='stylesheet' type='text/css'>
        <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Qwigley" >
        <!-- Font awesome -->
        <link href="font-awesome-4.1.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">

   </head>
   <body>
   
   <!-- Start wrapper -->
   <div class="wrapper">
  	  <div class="col-md-12">
         <!-- Logo -->
         <div class="brand wow fadeIn" data-wow-delay="0.1s"> Yangbin Chen
           <div class="title"> - dongyiwu92 [AT] gmail [DOT] com -  </div>
         </div>

         <!-- Navigation -->
         <nav class="navbar navbar-default" role="navigation">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <!-- navbar-brand is hidden on larger screens, but visible when the menu is collapsed -->
                <div class="navbar-brand"><a href="">Yangbin Chen</a>
                <div class="title"> - dongyiwu92 [AT] gmail [DOT] com - </div>
                </div>
                 
            </div>
            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav">
                   <li>
                      <a href="index.html">Home</a>
                    <li>
                    <li>
                       <a href="about.html">About</a>
                    </li>
                    <li class="active">
                       <a href="publication.html">Publication</a>
                    </li>
                    <li>
                       <a  href="resume.html">Resume</a>
                    </li>
                    <li>
                       <a href="news.html">News</a>
                    </li>
                    <li>
                      <a href="contact.html">Contact</a>
                    </li>
                </ul>
            </div>
            <!-- /navbar-collapse -->
         </nav>
         <!-- End nav -->


         <!-- Start margin -->
         <div class="margin-publication wow fadeIn" data-wow-delay="0.1s">
             <div class="col-md-10 col-xs-offset-1">
               <h4 class="heading-inner">Publication</h4>
                  <div class="hr"></div>
                   <div class="holder wow fadeIn" data-wow-delay="0.1s">
               <h4>Journal Articles</h4>

      <ul>
		  <li><p>
			<b>An Active Learning-based Alternative Reinforcement Contextual Information Fusion Model for Multimodal Sentiment Analysis</b> [<a href="https://doi.org/10.1109/TASLPRO.2025.3597474">paper</a>] <br>
			  Xiaojiang He, Yushan Pan, <u>Yangbin Chen</u>, Zuhe Li, Zhijie Xu, Chengguang Yang, and Kaiwei Wang <br>
			  In <i>IEEE Transactions on Audio, Speech and Language Processing (<b>TASLP</b>), 2025</i>
		  </p></li>
		  
		<li><p>
          <b>Deep Learning-based Detection of Depression by Fusing Auditory, Visual and Textual Clues</b> [<a href="https://doi.org/10.1016/j.jad.2025.119860">paper</a>] <br>
          Chenyang Xu, <u>Yangbin Chen</u>, Yanbao Tao, Wanqing Xie, Xiaofeng Liu, Yunhan Lin, Chunfeng Liang, Fan Du, Zhixiong Lin, Chuan Shi <br>
          In <i>Journal of Affective Disorders, 2025</i>
        </p></li> 
		<li><p>
          <b>Wide‐Bandwidth Nanocomposite‐Sensor Integrated Smart Mask for Tracking Multiphase Respiratory Activities</b> [<a href="https://onlinelibrary.wiley.com/doi/full/10.1002/advs.202203565">paper</a>] <br>
          Yao Suo, Yifan Liu, Cong Wu, Meng Chen, Qingyun Huang, Yiming Liu, Kuanming Yao, <u>Yangbin Chen</u>, Qiqi Pan, Xiaoyu Chang, Alice Yeuk Lan Leung, Ho‐yin Chan, Guanglie Zhang, Zhengbao Yang, Walid Daoud, Xinyue Li, Vellaisamy AL Roy, Jiangang Shen, Xinge Yu, Jianping Wang, and Wen Jung Li <br>
          In <i>Advanced Science, 2022</i>
        </p></li>     
        <li><p>
          <b>Multi-Task Learning for Abstractive and Extractive Summarization</b> [<a href="https://link.springer.com/article/10.1007/s41019-019-0087-7">paper</a>] [<a href="https://github.com/Codelegant92/MTL_Abs_Ext_Sum">code</a>]<br>
          <u>Yangbin Chen</u>, Yun Ma, Xudong Mao, and Qing Li<br>
          In <i>Data Science and Engineering, 2019</i>
        </p></li>
        <li><p>
          <b>Design and Evaluate Immersive Learning Experience for Massive Open Online Courses (MOOCs)</b> [<a href="https://ieeexplore.ieee.org/document/8515107">paper</a>]<br>
          Horace H.S. Ip, Chen Li, Selena Leoni, <u>Yangbin Chen</u>, Ka-Fai Ma, Calvin Hoito Wong, and Qing Li<br>
          In <i>IEEE Transactions on Learning Technologies, 2018</i>
        </p></li>
      </ul>


      <h4>Conference Papers</h4>

      <ul>
		<li><p>
			<b>SEVADE: Self-Evolving Multi-Agent Analysis with Decoupled Evaluation for Hallucination-Resistant Sarcasm Detection</b> [<a href="https://arxiv.org/abs/2508.06803">paper</a>] [<a href="https://github.com/sunbus100/SEVADE">code</a>] <br>
			Ziqi Liu<sup>*</sup>, Ziyang Zhou<sup>*</sup>, Yilin Li, Mingxuan Hu, Yushan Pan, Zhijie Xu, and <u>Yangbin Chen</u><sup>†</sup><br>
			In <i>32nd International Conference on Neural Information Processing (<b>ICONIP</b>), 2025</i>
		</p></li>
		  
		<li><p>
			<b>CAF-I: A Collaborative Multi-Agent Framework for Enhanced Irony Detection with Large Language Models</b> [<a href="https://openreview.net/forum?id=wVXNpw2amK&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3Dapnns.org%2FICONIP%2F2025%2FConference%2FAuthors%23your-submissions)">paper</a>] <br>
			Ziqi Liu, Ziyang Zhou, Mingxuan Hu, <u>Yangbin Chen</u><sup>†</sup>, and Zhijie Xu <br>
			In <i>32nd International Conference on Neural Information Processing (<b>ICONIP</b>), 2025</i>
		</p></li>
		  
		<li><p>
			  <b>An Active Learning-based Global-Distribution Attention Model for Multimodal Sentiment Analysis</b> <br>
			  Xiaojiang He, Yushan Pan, Nan Xiang, <u>Yangbin Chen</u>, and Zhijie Xu <br>
			  In <i>13th International Conference on Affective Computing and Intelligent Interaction (<b>ACII</b>), 2025</i>
		</p></li>

		<li><p>
          <b>Speech-based Clinical Depression Screening: An Empirical Study</b> [<a href="https://doi.org/10.1109/ICASSPW65056.2025.11011046">paper</a>] <br>
          <u>Yangbin Chen</u>, Chenyang Xu, Chunfeng Liang, Yanbao Tao, and Chuan Shi<sup>†</sup><br>
          In <i>Proceedings of International Conference on Acoustics, Speech and Signal Processing Workshops(<b>ICASSPW</b>), 2025</i>
        </p></li>
		  
		<li><p>
          <b>Wish I Can Feel What You Feel: A Neural Approach for Empathetic Response Generation</b> [<a href="https://preview.aclanthology.org/emnlp-22-ingestion/2022.findings-emnlp.65/">paper</a>] <br>
          <u>Yangbin Chen</u> and Chunfeng Liang<br>
          In <i>Findings of the 2022 Conference on Empirical Methods in Natural Language Processing (<b>EMNLP</b>), 2022</i>
        </p></li>
        <li><p>
          <b>Collaborative Learning of Bidirectional Decoders for Unsupervised Text Style Transfer</b> [<a href="https://aclanthology.org/2021.emnlp-main.729/">paper</a>] <!--[<a href="https://github.com/
		  sunlight-ym/CBD_style_transfer.">code</a>]--> <br>
          Yun Ma, <u>Yangbin Chen</u>, Xudong Mao, and Qing Li<br>
          In <i>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (<b>EMNLP</b>), 2021</i>
        </p></li>
        <li><p>
          <b>A Meta-learning Approach for User-defined Spoken Term Classification with Varying Classes and Examples</b> [<a href="https://www.isca-speech.org/archive/pdfs/interspeech_2021/chen21u_interspeech.pdf">paper</a>] [<a href="https://github.com/Codelegant92/STC-ProtoNet">code</a>] [<a href="pdf/interspeech2021_STC-ProtoNet.pdf">slides</a>] <br>
          <u>Yangbin Chen</u>, Tom Ko, and Jianping Wang<br>
          In <i>Proceedings of Interspeech, 2021</i>
        </p></li>
        <li><p>
          <b>MetaMix: Improved Meta-Learning with Interpolation based Consistency Regularization</b> [<a href="https://ieeexplore.ieee.org/document/9413158">paper</a>] [<a href="pdf/ICPR_metamix_slides.pdf">slides</a>]<br>
          <u>Yangbin Chen</u>, Yun Ma, Tom Ko, Jianping Wang, and Qing Li<br>
          In <i>Proceedings of 25th International Conference on Pattern Recognition (<b>ICPR</b>), 2020</i>
        </p></li>
        <li><p>
          <b>An Investigation of Few-Shot Learning in Spoken Term Classification</b> [<a href="https://www.isca-speech.org/archive/Interspeech_2020/pdfs/2568.pdf">paper</a>] [<a href="https://github.com/Codelegant92/STC-MAML-PyTorch">code</a>] [<a href="pdf/interspeech_maml_stc_slides.pdf">slides</a>]<br>
          <u>Yangbin Chen</u>, Tom Ko, Lifeng Shang, Xiao Chen, Xin Jiang, and Qing Li<br>
          In <i>Proceedings of Interspeech, 2020</i>
        </p></li>
        <li><p>
          <b>Prototypical Networks for Small Footprint Text-Independent Speaker Verification</b> [<a href="https://ieeexplore.ieee.org/document/9054471">paper</a>] [<a href="pdf/icassp_protonet_sv_slides.pdf">slides</a>]<br>
          Tom Ko, <u>Yangbin Chen</u>, and Qing Li<br>
          In <i>Proceedings of International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>), 2020</i>
        </p></li>
        <li><p>
          <b>Generating Adversarial Examples by Adversarial Networks for Semi-supervised Learning</b> [<a href="https://link.springer.com/chapter/10.1007/978-3-030-34223-4_8">paper</a>] [<a href="pdf/WISE2019.pdf">slides</a>]<br>
          Yun Ma, Xudong Mao, <u>Yangbin Chen</u>, and Qing Li<br>
          In <i>Proceedings of International Conference on Web Information Systems Engineering (<b>WISE</b>), 2020</i>
        </p></li>
        <li><p>
          <b>Mixing Up Real Samples and Adversarial Samples for Semi-supervised Learning</b> [<a href="https://ieeexplore.ieee.org/abstract/document/9207038/">paper</a>] [<a href="pdf/IJCNN2020.pdf">slides</a>]<br>
          Yun Ma, Xudong Mao, <u>Yangbin Chen</u>, and Qing Li<br>
          In <i>Proceedings of International Joint Conference on Neural Networks (<b>IJCNN</b>), 2020</i>
        </p></li>
        <li><p>
          <b>Abstractive Summarization with the Aid of Extractive Summarization</b> [<a href="https://link.springer.com/chapter/10.1007/978-3-319-96890-2_1">paper</a>] [<a href="pdf/APWeb-WAIM_sum_slides.pdf">slides</a>]<br>
          <u>Yangbin Chen</u>, Yun Ma, Xudong Mao, Qing Li<br>
          In <i> Proceedings of Asia-Pacific Web (<b>APWeb</b>) and Web-Age Information Management (<b>WAIM</b>) Joint International Conference on Web and Big Data, 2018</i>
        </p></li>

      </ul>
        
      <h4>Preprint Papers</h4>
      <ul>
		  
        <li><p>
          <b>Virtual Mixup Training for Unsupervised Domain Adaptation</b> [<a href="https://arxiv.org/abs/1905.04215">paper</a>] [<a href="https://github.com/xudonmao/VMT">code</a>]<br>
          Xudong Mao, Yun Ma, Zhenguo Yang, <u>Yangbin Chen</u>, and Qing Li<br>
          In <i>arXiv preprint arXiv:1905.04215, 2019</i>
        </p></li>
      </ul>
       
          </div>
          <!-- End margin -->

          <!-- Start footer -->
          <div class="footer col-md-6 col-xs-offset-3">
              <h5>Copyright 2025
              <a href="https://scholar.google.com/citations?hl=zh-TW&user=87OYj0YAAAAJ&view_op=list_works&sortby=pubdate"><i class="fa fa-google fa-1x icon1"></i></a>
                 <a href="https://github.com/Codelegant92"><i class="fa fa-github fa-1x icon1"></i></a>
                 <a href="https://www.linkedin.com/in/yangbinchen/"><i class="fa fa-linkedin fa-1x icon1"></i></a>
                 <a href="#"><i class="fa fa-instagram fa-1x icon1"></i></a>
              </h5>
           </div>
           <!-- End footer -->

                  
      </div>
      <!-- End col-md-12 -->

   </div>
   <!-- End wrapper -->
   
      
   <!-- jQuery Version 1.11.0 -->
   <script src="js/jquery-1.11.0.js"></script>
   <!-- Boostrap JS -->
   <script src="js/bootstrap.min.js"></script>
   <!-- Isotope JS -->
   <script src="js/jquery.isotope.min.js"></script>
    <!-- Main JS -->
   <script src="js/main.js"></script>
   <!-- WOW JS -->
   <script src="js/wow.min.js"></script>
   <!-- Gallery JavaScript -->
    <script src="js/touchTouch.jquery.js"></script>
	<script src="js/script.js"></script>
   
    <!-- Smooth scroll JS -->
    <script src="js/smoothscroll.js"></script>
    
    <!-- Wow JavaScript -->
    <script src="js/wow.js"></script>
    
    <script>
    new WOW().init();
    </script>


</body>
</html>
